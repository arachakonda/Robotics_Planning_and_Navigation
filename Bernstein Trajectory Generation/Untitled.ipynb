{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "758e65b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-19 17:19:45.073932: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu:/usr/local/lib\n",
      "2022-03-19 17:19:45.073952: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5609760f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://linqs-data.soe.ucsc.edu/public/lbc/cora.tgz\n",
      "172032/168052 [==============================] - 10s 57us/step\n",
      "180224/168052 [================================] - 10s 54us/step\n"
     ]
    }
   ],
   "source": [
    "zip_file = keras.utils.get_file(\n",
    "    fname=\"cora.tgz\",\n",
    "    origin=\"https://linqs-data.soe.ucsc.edu/public/lbc/cora.tgz\",\n",
    "    extract=True,\n",
    ")\n",
    "data_dir = os.path.join(os.path.dirname(zip_file), \"cora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aaf9ae96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Citations shape: (5429, 2)\n"
     ]
    }
   ],
   "source": [
    "citations = pd.read_csv(\n",
    "    os.path.join(data_dir, \"cora.cites\"),\n",
    "    sep=\"\\t\",\n",
    "    header=None,\n",
    "    names=[\"target\", \"source\"],\n",
    ")\n",
    "print(\"Citations shape:\", citations.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db65cfca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4413</th>\n",
       "      <td>180373</td>\n",
       "      <td>180399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>3229</td>\n",
       "      <td>82087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4168</th>\n",
       "      <td>134199</td>\n",
       "      <td>447224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>14428</td>\n",
       "      <td>1103969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2787</th>\n",
       "      <td>33231</td>\n",
       "      <td>300071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      target   source\n",
       "4413  180373   180399\n",
       "862     3229    82087\n",
       "4168  134199   447224\n",
       "1978   14428  1103969\n",
       "2787   33231   300071"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "citations.sample(frac=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1748de8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Papers shape: (2708, 1435)\n"
     ]
    }
   ],
   "source": [
    "column_names = [\"paper_id\"] + [f\"term_{idx}\" for idx in range(1433)] + [\"subject\"]\n",
    "papers = pd.read_csv(\n",
    "    os.path.join(data_dir, \"cora.content\"), sep=\"\\t\", header=None, names=column_names,\n",
    ")\n",
    "print(\"Papers shape:\", papers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f940d2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_values = sorted(papers[\"subject\"].unique())\n",
    "class_idx = {name: id for id, name in enumerate(class_values)}\n",
    "paper_idx = {name: idx for idx, name in enumerate(sorted(papers[\"paper_id\"].unique()))}\n",
    "\n",
    "papers[\"paper_id\"] = papers[\"paper_id\"].apply(lambda name: paper_idx[name])\n",
    "citations[\"source\"] = citations[\"source\"].apply(lambda name: paper_idx[name])\n",
    "citations[\"target\"] = citations[\"target\"].apply(lambda name: paper_idx[name])\n",
    "papers[\"subject\"] = papers[\"subject\"].apply(lambda value: class_idx[value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b0f59a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (1289, 1435)\n",
      "Test data shape: (1419, 1435)\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = [], []\n",
    "\n",
    "for _, group_data in papers.groupby(\"subject\"):\n",
    "    # Select around 50% of the dataset for training.\n",
    "    random_selection = np.random.rand(len(group_data.index)) <= 0.5\n",
    "    train_data.append(group_data[random_selection])\n",
    "    test_data.append(group_data[~random_selection])\n",
    "\n",
    "train_data = pd.concat(train_data).sample(frac=1)\n",
    "test_data = pd.concat(test_data).sample(frac=1)\n",
    "\n",
    "print(\"Train data shape:\", train_data.shape)\n",
    "print(\"Test data shape:\", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aec30002",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_units = [32, 32]\n",
    "learning_rate = 0.01\n",
    "dropout_rate = 0.5\n",
    "num_epochs = 300\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc0ff1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(model, x_train, y_train):\n",
    "    # Compile the model.\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate),\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[keras.metrics.SparseCategoricalAccuracy(name=\"acc\")],\n",
    "    )\n",
    "    # Create an early stopping callback.\n",
    "    early_stopping = keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_acc\", patience=50, restore_best_weights=True\n",
    "    )\n",
    "    # Fit the model.\n",
    "    history = model.fit(\n",
    "        x=x_train,\n",
    "        y=y_train,\n",
    "        epochs=num_epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_split=0.15,\n",
    "        callbacks=[early_stopping],\n",
    "    )\n",
    "\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca573a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_ffn(hidden_units, dropout_rate, name=None):\n",
    "    fnn_layers = []\n",
    "\n",
    "    for units in hidden_units:\n",
    "        fnn_layers.append(layers.BatchNormalization())\n",
    "        fnn_layers.append(layers.Dropout(dropout_rate))\n",
    "        fnn_layers.append(layers.Dense(units, activation=tf.nn.gelu))\n",
    "\n",
    "    return keras.Sequential(fnn_layers, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca43ec3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_44397/3641831727.py:6: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  x_train = train_data[feature_names].to_numpy()\n",
      "/tmp/ipykernel_44397/3641831727.py:7: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  x_test = test_data[feature_names].to_numpy()\n"
     ]
    }
   ],
   "source": [
    "feature_names = set(papers.columns) - {\"paper_id\", \"subject\"}\n",
    "num_features = len(feature_names)\n",
    "num_classes = len(class_idx)\n",
    "\n",
    "# Create train and test features as a numpy array.\n",
    "x_train = train_data[feature_names].to_numpy()\n",
    "x_test = test_data[feature_names].to_numpy()\n",
    "# Create train and test targets as a numpy array.\n",
    "y_train = train_data[\"subject\"]\n",
    "y_test = test_data[\"subject\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0c0e28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edges shape: (2, 5429)\n",
      "Nodes shape: (2708, 1433)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_44397/2468639763.py:7: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  papers.sort_values(\"paper_id\")[feature_names].to_numpy(), dtype=tf.dtypes.float32\n"
     ]
    }
   ],
   "source": [
    "# Create an edges array (sparse adjacency matrix) of shape [2, num_edges].\n",
    "edges = citations[[\"source\", \"target\"]].to_numpy().T\n",
    "# Create an edge weights array of ones.\n",
    "edge_weights = tf.ones(shape=edges.shape[1])\n",
    "# Create a node features array of shape [num_nodes, num_features].\n",
    "node_features = tf.cast(\n",
    "    papers.sort_values(\"paper_id\")[feature_names].to_numpy(), dtype=tf.dtypes.float32\n",
    ")\n",
    "# Create graph info tuple with node_features, edges, and edge_weights.\n",
    "graph_info = (node_features, edges, edge_weights)\n",
    "\n",
    "print(\"Edges shape:\", edges.shape)\n",
    "print(\"Nodes shape:\", node_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3df57973",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GraphConvLayer(layers.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_units,\n",
    "        dropout_rate=0.2,\n",
    "        aggregation_type=\"mean\",\n",
    "        combination_type=\"concat\",\n",
    "        normalize=False,\n",
    "        *args,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super(GraphConvLayer, self).__init__(*args, **kwargs)\n",
    "\n",
    "        self.aggregation_type = aggregation_type\n",
    "        self.combination_type = combination_type\n",
    "        self.normalize = normalize\n",
    "\n",
    "        self.ffn_prepare = create_ffn(hidden_units, dropout_rate)\n",
    "        if self.combination_type == \"gated\":\n",
    "            self.update_fn = layers.GRU(\n",
    "                units=hidden_units,\n",
    "                activation=\"tanh\",\n",
    "                recurrent_activation=\"sigmoid\",\n",
    "                dropout=dropout_rate,\n",
    "                return_state=True,\n",
    "                recurrent_dropout=dropout_rate,\n",
    "            )\n",
    "        else:\n",
    "            self.update_fn = create_ffn(hidden_units, dropout_rate)\n",
    "\n",
    "    def prepare(self, node_repesentations, weights=None):\n",
    "        # node_repesentations shape is [num_edges, embedding_dim].\n",
    "        messages = self.ffn_prepare(node_repesentations)\n",
    "        if weights is not None:\n",
    "            messages = messages * tf.expand_dims(weights, -1)\n",
    "        return messages\n",
    "\n",
    "    def aggregate(self, node_indices, neighbour_messages):\n",
    "        # node_indices shape is [num_edges].\n",
    "        # neighbour_messages shape: [num_edges, representation_dim].\n",
    "        print(\"---------------\")\n",
    "        \n",
    "        print(\"-------------------\")\n",
    "        num_nodes = tf.math.reduce_max(node_indices) + 1\n",
    "        if self.aggregation_type == \"sum\":\n",
    "            aggregated_message = tf.math.unsorted_segment_sum(\n",
    "                neighbour_messages, node_indices, num_segments=num_nodes\n",
    "            )\n",
    "        elif self.aggregation_type == \"mean\":\n",
    "            aggregated_message = tf.math.unsorted_segment_mean(\n",
    "                neighbour_messages, node_indices, num_segments=num_nodes\n",
    "            )\n",
    "        elif self.aggregation_type == \"max\":\n",
    "            aggregated_message = tf.math.unsorted_segment_max(\n",
    "                neighbour_messages, node_indices, num_segments=num_nodes\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid aggregation type: {self.aggregation_type}.\")\n",
    "\n",
    "        return aggregated_message\n",
    "\n",
    "    def update(self, node_repesentations, aggregated_messages):\n",
    "        # node_repesentations shape is [num_nodes, representation_dim].\n",
    "        # aggregated_messages shape is [num_nodes, representation_dim].\n",
    "        if self.combination_type == \"gru\":\n",
    "            # Create a sequence of two elements for the GRU layer.\n",
    "            h = tf.stack([node_repesentations, aggregated_messages], axis=1)\n",
    "        elif self.combination_type == \"concat\":\n",
    "            # Concatenate the node_repesentations and aggregated_messages.\n",
    "            h = tf.concat([node_repesentations, aggregated_messages], axis=1)\n",
    "        elif self.combination_type == \"add\":\n",
    "            # Add node_repesentations and aggregated_messages.\n",
    "            h = node_repesentations + aggregated_messages\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid combination type: {self.combination_type}.\")\n",
    "\n",
    "        # Apply the processing function.\n",
    "        node_embeddings = self.update_fn(h)\n",
    "        if self.combination_type == \"gru\":\n",
    "            node_embeddings = tf.unstack(node_embeddings, axis=1)[-1]\n",
    "\n",
    "        if self.normalize:\n",
    "            node_embeddings = tf.nn.l2_normalize(node_embeddings, axis=-1)\n",
    "        return node_embeddings\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"Process the inputs to produce the node_embeddings.\n",
    "\n",
    "        inputs: a tuple of three elements: node_repesentations, edges, edge_weights.\n",
    "        Returns: node_embeddings of shape [num_nodes, representation_dim].\n",
    "        \"\"\"\n",
    "\n",
    "        node_repesentations, edges, edge_weights = inputs\n",
    "        # Get node_indices (source) and neighbour_indices (target) from edges.\n",
    "        node_indices, neighbour_indices = edges[0], edges[1]\n",
    "        \n",
    "        print(edges )\n",
    "        # neighbour_repesentations shape is [num_edges, representation_dim].\n",
    "        neighbour_repesentations = tf.gather(node_repesentations, neighbour_indices)\n",
    "\n",
    "        # Prepare the messages of the neighbours.\n",
    "        neighbour_messages = self.prepare(neighbour_repesentations, edge_weights)\n",
    "        # Aggregate the neighbour messages.\n",
    "        aggregated_messages = self.aggregate(node_indices, neighbour_messages)\n",
    "        # Update the node embedding with the neighbour messages.\n",
    "        return self.update(node_repesentations, aggregated_messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d4481576",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GNNNodeClassifier(tf.keras.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        graph_info,\n",
    "        num_classes,\n",
    "        hidden_units,\n",
    "        aggregation_type=\"sum\",\n",
    "        combination_type=\"concat\",\n",
    "        dropout_rate=0.2,\n",
    "        normalize=True,\n",
    "        *args,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super(GNNNodeClassifier, self).__init__(*args, **kwargs)\n",
    "\n",
    "        # Unpack graph_info to three elements: node_features, edges, and edge_weight.\n",
    "        node_features, edges, edge_weights = graph_info\n",
    "        self.node_features = node_features\n",
    "        self.edges = edges\n",
    "        self.edge_weights = edge_weights\n",
    "        # Set edge_weights to ones if not provided.\n",
    "        if self.edge_weights is None:\n",
    "            self.edge_weights = tf.ones(shape=edges.shape[1])\n",
    "        # Scale edge_weights to sum to 1.\n",
    "        self.edge_weights = self.edge_weights / tf.math.reduce_sum(self.edge_weights)\n",
    "\n",
    "        # Create a process layer.\n",
    "        self.preprocess = create_ffn(hidden_units, dropout_rate, name=\"preprocess\")\n",
    "        # Create the first GraphConv layer.\n",
    "        self.conv1 = GraphConvLayer(\n",
    "            hidden_units,\n",
    "            dropout_rate,\n",
    "            aggregation_type,\n",
    "            combination_type,\n",
    "            normalize,\n",
    "            name=\"graph_conv1\",\n",
    "        )\n",
    "        # Create the second GraphConv layer.\n",
    "        self.conv2 = GraphConvLayer(\n",
    "            hidden_units,\n",
    "            dropout_rate,\n",
    "            aggregation_type,\n",
    "            combination_type,\n",
    "            normalize,\n",
    "            name=\"graph_conv2\",\n",
    "        )\n",
    "        # Create a postprocess layer.\n",
    "        self.postprocess = create_ffn(hidden_units, dropout_rate, name=\"postprocess\")\n",
    "        # Create a compute logits layer.\n",
    "        self.compute_logits = layers.Dense(units=num_classes, name=\"logits\")\n",
    "\n",
    "    def call(self, input_node_indices):\n",
    "        # Preprocess the node_features to produce node representations.\n",
    "        x = self.preprocess(self.node_features)\n",
    "        # Apply the first graph conv layer.\n",
    "        x1 = self.conv1((x, self.edges, self.edge_weights))\n",
    "        # Skip connection.\n",
    "        x = x1 + x\n",
    "        # Apply the second graph conv layer.\n",
    "        x2 = self.conv2((x, self.edges, self.edge_weights))\n",
    "        # Skip connection.\n",
    "        x = x2 + x\n",
    "        # Postprocess node embedding.\n",
    "        x = self.postprocess(x)\n",
    "        # Fetch node embeddings for the input node_indices.\n",
    "        node_embeddings = tf.gather(x, input_node_indices)\n",
    "        # Compute logits\n",
    "        return self.compute_logits(node_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d9d763c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[  21  905  906 ... 2586 1874 2707]\n",
      " [   0    0    0 ... 1874 1876 1897]], shape=(2, 5429), dtype=int64)\n",
      "---------------\n",
      "-------------------\n",
      "tf.Tensor(\n",
      "[[  21  905  906 ... 2586 1874 2707]\n",
      " [   0    0    0 ... 1874 1876 1897]], shape=(2, 5429), dtype=int64)\n",
      "---------------\n",
      "-------------------\n",
      "GNN output shape: tf.Tensor(\n",
      "[[ 0.08098246  0.06674735  0.18349154 -0.13010329  0.05768083  0.0118704\n",
      "   0.02312298]\n",
      " [-0.01424179 -0.03955875  0.12506233 -0.02832608 -0.00788456  0.07701259\n",
      "   0.04436262]\n",
      " [ 0.00884601  0.04790467  0.1180381   0.02898693  0.02011021  0.07032447\n",
      "   0.14787799]], shape=(3, 7), dtype=float32)\n",
      "Model: \"gnn_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " preprocess (Sequential)     (2708, 32)                52804     \n",
      "                                                                 \n",
      " graph_conv1 (GraphConvLayer  multiple                 5888      \n",
      " )                                                               \n",
      "                                                                 \n",
      " graph_conv2 (GraphConvLayer  multiple                 5888      \n",
      " )                                                               \n",
      "                                                                 \n",
      " postprocess (Sequential)    (2708, 32)                2368      \n",
      "                                                                 \n",
      " logits (Dense)              multiple                  231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 67,179\n",
      "Trainable params: 63,481\n",
      "Non-trainable params: 3,698\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gnn_model = GNNNodeClassifier(\n",
    "    graph_info=graph_info,\n",
    "    num_classes=num_classes,\n",
    "    hidden_units=hidden_units,\n",
    "    dropout_rate=dropout_rate,\n",
    "    name=\"gnn_model\",\n",
    ")\n",
    "\n",
    "print(\"GNN output shape:\", gnn_model([1, 10, 100]))\n",
    "\n",
    "gnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "75ae1538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "---------------\n",
      "-------------------\n",
      "---------------\n",
      "-------------------\n",
      "---------------\n",
      "-------------------\n",
      "---------------\n",
      "-------------------\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "1/5 [=====>........................] - ETA: 9s - loss: 2.3695 - acc: 0.1484[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "2/5 [===========>..................] - ETA: 0s - loss: 2.3154 - acc: 0.1562[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "3/5 [=================>............] - ETA: 0s - loss: 2.2125 - acc: 0.1784[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "4/5 [=======================>......] - ETA: 0s - loss: 2.1653 - acc: 0.1924[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "5/5 [==============================] - ETA: 0s - loss: 2.1559 - acc: 0.1973---------------\n",
      "-------------------\n",
      "---------------\n",
      "-------------------\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "5/5 [==============================] - 3s 199ms/step - loss: 2.1559 - acc: 0.1973 - val_loss: 1.9033 - val_acc: 0.3196\n",
      "Epoch 2/300\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.9039 - acc: 0.2656[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "2/5 [===========>..................] - ETA: 0s - loss: 1.9318 - acc: 0.2598[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "3/5 [=================>............] - ETA: 0s - loss: 1.9619 - acc: 0.2474[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "4/5 [=======================>......] - ETA: 0s - loss: 1.9534 - acc: 0.2598[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.9550 - acc: 0.2575[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 1.9550 - acc: 0.2575 - val_loss: 1.8883 - val_acc: 0.3144\n",
      "Epoch 3/300\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.9423 - acc: 0.2695[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "2/5 [===========>..................] - ETA: 0s - loss: 1.9439 - acc: 0.2559[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "3/5 [=================>............] - ETA: 0s - loss: 1.9340 - acc: 0.2604[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "4/5 [=======================>......] - ETA: 0s - loss: 1.9146 - acc: 0.2725[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.9144 - acc: 0.2731[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 1.9144 - acc: 0.2731 - val_loss: 1.8873 - val_acc: 0.3196\n",
      "Epoch 4/300\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.8454 - acc: 0.2930[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "2/5 [===========>..................] - ETA: 0s - loss: 1.8913 - acc: 0.3008[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "3/5 [=================>............] - ETA: 0s - loss: 1.8823 - acc: 0.2878[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "4/5 [=======================>......] - ETA: 0s - loss: 1.8835 - acc: 0.2852[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.8883 - acc: 0.2858[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 1.8883 - acc: 0.2858 - val_loss: 1.8840 - val_acc: 0.3196\n",
      "Epoch 5/300\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.8554 - acc: 0.2969[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "2/5 [===========>..................] - ETA: 0s - loss: 1.8541 - acc: 0.2910[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "3/5 [=================>............] - ETA: 0s - loss: 1.8410 - acc: 0.2969[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "4/5 [=======================>......] - ETA: 0s - loss: 1.8590 - acc: 0.2812[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.8520 - acc: 0.2913[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "5/5 [==============================] - 0s 80ms/step - loss: 1.8520 - acc: 0.2913 - val_loss: 1.8756 - val_acc: 0.3196\n",
      "Epoch 6/300\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.8900 - acc: 0.2891[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "2/5 [===========>..................] - ETA: 0s - loss: 1.8313 - acc: 0.3105[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "3/5 [=================>............] - ETA: 0s - loss: 1.8488 - acc: 0.2852[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "4/5 [=======================>......] - ETA: 0s - loss: 1.8542 - acc: 0.2803[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.8567 - acc: 0.2804[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "5/5 [==============================] - 0s 79ms/step - loss: 1.8567 - acc: 0.2804 - val_loss: 1.8637 - val_acc: 0.3196\n",
      "Epoch 7/300\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.8264 - acc: 0.3125[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "2/5 [===========>..................] - ETA: 0s - loss: 1.8176 - acc: 0.3105[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "3/5 [=================>............] - ETA: 0s - loss: 1.8274 - acc: 0.3047[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "4/5 [=======================>......] - ETA: 0s - loss: 1.8382 - acc: 0.3047[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.8398 - acc: 0.3050[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 1.8398 - acc: 0.3050 - val_loss: 1.8588 - val_acc: 0.3196\n",
      "Epoch 8/300\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.8372 - acc: 0.2891[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "2/5 [===========>..................] - ETA: 0s - loss: 1.8264 - acc: 0.2930[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "3/5 [=================>............] - ETA: 0s - loss: 1.8510 - acc: 0.2917[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "4/5 [=======================>......] - ETA: 0s - loss: 1.8368 - acc: 0.2998[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.8342 - acc: 0.3005[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 1.8342 - acc: 0.3005 - val_loss: 1.8525 - val_acc: 0.3196\n",
      "Epoch 9/300\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.8367 - acc: 0.2812[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "2/5 [===========>..................] - ETA: 0s - loss: 1.8063 - acc: 0.3066[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "3/5 [=================>............] - ETA: 0s - loss: 1.7972 - acc: 0.3125[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "4/5 [=======================>......] - ETA: 0s - loss: 1.7960 - acc: 0.3047[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.7998 - acc: 0.3078[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 1.7998 - acc: 0.3078 - val_loss: 1.8436 - val_acc: 0.3196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/300\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.7885 - acc: 0.3164[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "2/5 [===========>..................] - ETA: 0s - loss: 1.7891 - acc: 0.3105[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "3/5 [=================>............] - ETA: 0s - loss: 1.7915 - acc: 0.3151[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "4/5 [=======================>......] - ETA: 0s - loss: 1.8069 - acc: 0.3135[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.8131 - acc: 0.3078[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "5/5 [==============================] - 0s 79ms/step - loss: 1.8131 - acc: 0.3078 - val_loss: 1.8367 - val_acc: 0.3196\n",
      "Epoch 11/300\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.8067 - acc: 0.2891[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "2/5 [===========>..................] - ETA: 0s - loss: 1.7969 - acc: 0.3047[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "3/5 [=================>............] - ETA: 0s - loss: 1.8072 - acc: 0.3008[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "4/5 [=======================>......] - ETA: 0s - loss: 1.8073 - acc: 0.3047[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.8144 - acc: 0.2986[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 1.8144 - acc: 0.2986 - val_loss: 1.8305 - val_acc: 0.3196\n",
      "Epoch 12/300\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.7489 - acc: 0.3281[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "2/5 [===========>..................] - ETA: 0s - loss: 1.7979 - acc: 0.2891[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "3/5 [=================>............] - ETA: 0s - loss: 1.7970 - acc: 0.2917[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "4/5 [=======================>......] - ETA: 0s - loss: 1.7799 - acc: 0.2998[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.7889 - acc: 0.3014[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 1.7889 - acc: 0.3014 - val_loss: 1.8228 - val_acc: 0.3196\n",
      "Epoch 13/300\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.8193 - acc: 0.3008[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "2/5 [===========>..................] - ETA: 0s - loss: 1.7754 - acc: 0.3223[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "3/5 [=================>............] - ETA: 0s - loss: 1.7825 - acc: 0.3086[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "4/5 [=======================>......] - ETA: 0s - loss: 1.7799 - acc: 0.3096[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.7815 - acc: 0.3068[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 1.7815 - acc: 0.3068 - val_loss: 1.8136 - val_acc: 0.3196\n",
      "Epoch 14/300\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.7474 - acc: 0.3125[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "2/5 [===========>..................] - ETA: 0s - loss: 1.7668 - acc: 0.3066[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n",
      "3/5 [=================>............] - ETA: 0s - loss: 1.7863 - acc: 0.2956[21 905 906 ... 2586 1874 2707]\n",
      "[21 905 906 ... 2586 1874 2707]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m x_train \u001b[38;5;241m=\u001b[39m train_data\u001b[38;5;241m.\u001b[39mpaper_id\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[0;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgnn_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36mrun_experiment\u001b[0;34m(model, x_train, y_train)\u001b[0m\n\u001b[1;32m      9\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(\n\u001b[1;32m     10\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_acc\u001b[39m\u001b[38;5;124m\"\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Fit the model.\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.15\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m history\n",
      "File \u001b[0;32m~/Documents/TDL/TDL2022/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Documents/TDL/TDL2022/lib/python3.8/site-packages/keras/engine/training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1379\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1380\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1381\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1382\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1383\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1384\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1385\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1386\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/Documents/TDL/TDL2022/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Documents/TDL/TDL2022/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Documents/TDL/TDL2022/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/Documents/TDL/TDL2022/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2954\u001b[0m   (graph_function,\n\u001b[1;32m   2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/TDL/TDL2022/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m     args,\n\u001b[1;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1858\u001b[0m     executing_eagerly)\n\u001b[1;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Documents/TDL/TDL2022/lib/python3.8/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/Documents/TDL/TDL2022/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x_train = train_data.paper_id.to_numpy()\n",
    "history = run_experiment(gnn_model, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99fbb126",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'display_learning_curves' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdisplay_learning_curves\u001b[49m(history)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'display_learning_curves' is not defined"
     ]
    }
   ],
   "source": [
    "display_learning_curves(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a266709",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1c1e2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2337601a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TDL2022",
   "language": "python",
   "name": "tdl2022"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
